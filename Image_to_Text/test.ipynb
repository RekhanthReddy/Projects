{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e255245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760f26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break this down!\n",
      "\n",
      "First, it's important to know that \"Model Context Protocol\" isn't a standard, official term that everyone uses. It sounds like it's talking about **how AI models handle and use the information you give them**.\n",
      "\n",
      "Think of an AI model, like the one you're talking to now, like a super-smart student.\n",
      "\n",
      "1.  **What is \"Context\"?**\n",
      "    *   Imagine you're talking to your teacher. If you just say \"It's over there!\", your teacher won't know what \"It\" is or where \"there\" is. You need to give them **context**.\n",
      "    *   Context means the surrounding information â€“ like what you were talking about before, what the question is, or what situation you're in.\n",
      "    *   For an AI model, context is the text you give it to work with. This could be your question, the beginning of a story you want it to finish, or the whole conversation you've had so far.\n",
      "\n",
      "2.  **The Challenge: Limited Memory (The \"Context Window\")**\n",
      "    *   Unlike a human who can remember a whole long conversation, AI models (especially the big ones that generate text) have a limited \"short-term memory\" for the conversation or text they are currently working on.\n",
      "    *   Think of it like a small window you're looking through. You can only see what's *inside* that window right now. The model can only \"see\" and process the information that fits within its **context window**.\n",
      "    *   This window has a size limit (measured in something called \"tokens,\" which are like words or pieces of words).\n",
      "\n",
      "3.  **What \"Model Context Protocol\" Likely Means (How it Works/The Rules):**\n",
      "    *   Since \"protocol\" often means \"a set of rules\" or \"the way something works,\" \"Model Context Protocol\" probably refers to **how the AI model manages and uses the information within its limited context window.**\n",
      "    *   Here's what those \"rules\" or \"how it works\" generally involve:\n",
      "        *   **Reading the Input:** The model reads your text (your question, the previous turns in the conversation, etc.).\n",
      "        *   **Filling the Window:** It loads as much of that text as it can into its context window, starting with the most recent information (like the last few messages in a chat).\n",
      "        *   **Using Only What's Visible:** The model uses *only* the information that is currently *inside* its context window to figure out what to say or do next.\n",
      "        *   **Forgetting Old Stuff:** If the conversation goes on for too long, the *oldest* information in the context window gets pushed out as new information comes in. The model \"forgets\" what was said way back at the start.\n",
      "\n",
      "**In simple terms, for a school student:**\n",
      "\n",
      "Imagine you have a small notepad where you keep notes for a project.\n",
      "*   **Context:** All the information you've gathered for your project.\n",
      "*   **Context Window:** The small notepad itself. You can only write so much on it.\n",
      "*   **\"Model Context Protocol\" (How it works):** It's like the rules of using your notepad:\n",
      "    1.  You write down new important notes.\n",
      "    2.  You use *only* the notes currently *on the pad* to decide what to do next.\n",
      "    3.  If the pad gets full, you have to erase the oldest notes to make space for new ones. You can no longer see or use the notes you erased.\n",
      "\n",
      "So, when someone talks about how an AI model handles context, they are usually talking about its limited \"memory\" (the context window) and **how it reads, uses, and eventually forgets information as the conversation or text gets longer.** It's the system by which the model tries to understand what's happening *right now* based on the immediate past, but it can't remember everything from the very beginning if the interaction is very long.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= 'AIzaSyAPhaT7qi_-QAlHXvSh5LFgw5twWrW-brI')\n",
    "\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash-preview-04-17')\n",
    "response = model.generate_content('What is the model contect protocol? can you explain to school student?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f0e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you're in a play. You're an actor, and the play is called \"Solving a Mystery.\"\n",
      "\n",
      "**What's the Play About? (Context)**\n",
      "\n",
      "*   The play needs to have a setting (a spooky mansion!), characters (a detective, a butler, a suspicious aunt!), and a plot (someone stole a valuable painting!).\n",
      "*   All these things together create the **context** of the play. It's the background information that helps everyone understand what's happening.\n",
      "\n",
      "**What's Your Job? (The Model)**\n",
      "\n",
      "*   You, as an actor, need to understand the play's context *really* well. You need to know:\n",
      "    *   Where you are (the mansion).\n",
      "    *   Who you're talking to (the butler).\n",
      "    *   What's going on (the painting is missing!).\n",
      "*   Knowing all this context helps you deliver your lines believably, react appropriately, and make good decisions about your character's actions.\n",
      "\n",
      "**The Model Context Protocol (The Script and Rehearsals)**\n",
      "\n",
      "*   The **Model Context Protocol** is like the script and rehearsals for the AI (the \"actor\") that's solving a problem. It's a way of making sure the AI has the right context to do its job well.\n",
      "*   It involves carefully *preparing* the information about the problem so the AI can understand it. This might involve:\n",
      "    *   **Explaining the rules:** Like saying \"You are a detective, and your goal is to find the painting.\"\n",
      "    *   **Providing relevant facts:** \"The painting was last seen in the library. The butler was the last person to see it.\"\n",
      "    *   **Giving examples:** \"In similar cases, the thief often had a motive related to money or revenge.\"\n",
      "\n",
      "**Why is this important?**\n",
      "\n",
      "Imagine if you, the actor, didn't know the painting was stolen! You might start asking about what's for dinner instead of investigating the crime. The AI is similar! If you don't provide the necessary context, it might not understand the problem and give you a useless answer.\n",
      "\n",
      "**In Summary**\n",
      "\n",
      "The Model Context Protocol is about giving an AI model all the necessary background information (the \"context\") so it can:\n",
      "\n",
      "1.  Understand the problem it's supposed to solve.\n",
      "2.  Solve the problem accurately and effectively.\n",
      "3.  Act in a relevant and helpful way.\n",
      "\n",
      "Just like you need to understand the play to be a good actor, the AI needs the right context to be a good problem-solver!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyAPhaT7qi_-QAlHXvSh5LFgw5twWrW-brI')  # Use your actual API key\n",
    "\n",
    "model = genai.GenerativeModel('models/gemini-2.0-flash')  # Double-check this\n",
    "\n",
    "response = model.generate_content(\"What is the model context protocol? Can you explain it to a school student?\")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac02089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
